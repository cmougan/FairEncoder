{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eae22df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "#from pandas_profiling import ProfileReportofileReport\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1512bb96",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from fairlearn.metrics import MetricFrame\n",
    "from fairlearn.metrics import selection_rate, false_positive_rate,true_positive_rate,count\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression,Lasso\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "\n",
    "from xgboost import XGBRegressor,XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import shap\n",
    "\n",
    "from category_encoders.target_encoder import TargetEncoder\n",
    "from category_encoders.m_estimate import MEstimateEncoder\n",
    "from category_encoders.cat_boost import CatBoostEncoder\n",
    "from category_encoders.leave_one_out import LeaveOneOutEncoder\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c83bdffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/so2019.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c990962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the target\n",
    "df[\"Score\"] = df[\"convertedcomp\"]\n",
    "\n",
    "df.loc[df[\"convertedcomp\"] >  df.convertedcomp.median(), \"Score\"] = 1\n",
    "df.loc[df[\"convertedcomp\"] <= df.convertedcomp.median(), \"Score\"] = 0\n",
    "\n",
    "# Data cleaning\n",
    "df.yearscode = df.yearscode.replace('Less than 1 year',1)\n",
    "df.yearscode = df.yearscode.replace('More than 50 years',50)\n",
    "df.yearscode = df.yearscode.replace(np.nan,0)\n",
    "df.yearscode= df.yearscode.astype(int)\n",
    "df = df.fillna(df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "816d2bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df.drop(columns=['convertedcomp','Score'])\n",
    "y = df[[\"Score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4436fa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c8c8887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_predict(modelo, enc, data, target, test):\n",
    "    pipe = Pipeline([(\"encoder\", enc), (\"model\", modelo)])\n",
    "    pipe.fit(data, target)\n",
    "    return pipe.predict(test)\n",
    "\n",
    "\n",
    "def auc_group(model, data, y_true, dicc, group: str = \"\", min_samples: int = 500):\n",
    "\n",
    "    aux = data.copy()\n",
    "    aux[\"target\"] = y_true\n",
    "    cats = aux[group].value_counts()\n",
    "    cats = cats[cats > min_samples].index.tolist()\n",
    "    cats = cats + [\"all\"]\n",
    "\n",
    "    if len(dicc) == 0:\n",
    "        dicc = defaultdict(list, {k: [] for k in cats})\n",
    "\n",
    "    for cat in cats:\n",
    "        if cat != \"all\":\n",
    "            aux2 = aux[aux[group] == cat]\n",
    "            preds = model.predict_proba(aux2.drop(columns=\"target\"))[:, 1]\n",
    "            truth = aux2[\"target\"]\n",
    "            dicc[cat].append(roc_auc_score(truth, preds))\n",
    "        elif cat == \"all\":\n",
    "            dicc[cat].append(roc_auc_score(y_true, model.predict_proba(data)[:, 1]))\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    return dicc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aec17b0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4468462adb7842438ca9430eea60ec50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found 143 subgroups. Evaluation may be slow\n",
      "Found 143 subgroups. Evaluation may be slow\n",
      "Found 143 subgroups. Evaluation may be slow\n",
      "Found 143 subgroups. Evaluation may be slow\n",
      "Found 143 subgroups. Evaluation may be slow\n",
      "Found 143 subgroups. Evaluation may be slow\n",
      "Found 143 subgroups. Evaluation may be slow\n",
      "Found 143 subgroups. Evaluation may be slow\n",
      "Found 143 subgroups. Evaluation may be slow\n",
      "Found 143 subgroups. Evaluation may be slow\n",
      "Found 143 subgroups. Evaluation may be slow\n",
      "Found 143 subgroups. Evaluation may be slow\n",
      "Found 143 subgroups. Evaluation may be slow\n",
      "Found 143 subgroups. Evaluation may be slow\n",
      "Found 143 subgroups. Evaluation may be slow\n"
     ]
    }
   ],
   "source": [
    "for metrics in [selection_rate, false_positive_rate, true_positive_rate]:\n",
    "    MIN_SAMPLES=499\n",
    "    gms = []\n",
    "    gms_rec = []\n",
    "    ms = []\n",
    "    auc = {}\n",
    "\n",
    "    #param = [0, 1,2, 5, 10, 20, 50, 100]\n",
    "    param = np.linspace(0,1,20)\n",
    "    for m in tqdm(param):\n",
    "        encoder = MEstimateEncoder(m=m)\n",
    "        #encoder = TargetEncoder(smoothing=m)\n",
    "        encoder = LeaveOneOutEncoder(sigma=m)\n",
    "        \n",
    "        #model = LogisticRegression()\n",
    "        model = GradientBoostingClassifier()\n",
    "\n",
    "        pipe = Pipeline([(\"encoder\", encoder), (\"model\", model)])\n",
    "        pipe.fit(X_tr, y_tr)\n",
    "        preds = pipe.predict(X_te)\n",
    "\n",
    "        gm = MetricFrame(\n",
    "            metrics=metrics,\n",
    "            y_true=y_te,\n",
    "            y_pred=preds,\n",
    "            sensitive_features=X_te[\"country\"],\n",
    "        )\n",
    "        auc = auc_group(\n",
    "            model=pipe, data=X_te, y_true=y_te, dicc=auc, group=\"country\",min_samples=MIN_SAMPLES\n",
    "        )\n",
    "        \n",
    "        gms.append(gm)\n",
    "        ms.append(m)\n",
    "\n",
    "\n",
    "\n",
    "    # Ethnic\n",
    "    plt.figure()\n",
    "    title = \"Impact of encoding regularization in category fairness \" + str(\n",
    "        metrics.__name__\n",
    "    )\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"M parameter\")\n",
    "    plt.plot(ms, [gm.overall for gm in gms], label=\"Overall\")\n",
    "    \n",
    "\n",
    "    for element in auc.keys():\n",
    "        try:\n",
    "            plt.plot(ms, [gm.by_group[element] for gm in gms], label=element)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    plt.legend(bbox_to_anchor=(1.1, 1))\n",
    "    plt.show()\n",
    "\n",
    "    # AUC ROC\n",
    "    plt.title(\"AUC ROC\")\n",
    "    plt.xlabel(\"M parameter\")\n",
    "    plt.plot(ms, auc[\"all\"], label=\"Overall\")\n",
    "    for element in auc.keys():\n",
    "        plt.plot(ms, auc[element], label=element)\n",
    "\n",
    "    plt.legend(bbox_to_anchor=(1.1, 1))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e1a7da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd50587",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e261369",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b0a5df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04fb272",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quantile",
   "language": "python",
   "name": "quantile"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
